---
title: "Prediction Assignment Writeup"
author: "VM"
date: "March 5, 2016"
output:
  pdf_document: default
  html_document:
    keep_md: yes
---

#OverView

The goal of your project is to predict the manner in which exercise is done.  
This is the "classe" variable in the training set. You may use any of the other variables to predict with.

**1)You should create a report describing how you built your model**  
**2)how you used cross validation**  
**3)what you think the expected out of sample error**  
**4)why you made the choices you did**

**DATA SAMPLE INFO**  

goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants.  
They were asked to perform barbell lifts correctly and incorrectly in 5 different ways

****Loading requried libraries****
```{r, warning=FALSE, message=FALSE}
  library(Hmisc)
  library(caret)
  library(randomForest)
  library(gbm)
  set.seed(2016)
```

##Data Loading and cleansing
```{r}
  trainDataRaw<- read.csv("pml-training.csv", na.strings = c("","NA", "NULL"))
  testDataRaw<- read.csv("pml-testing.csv", na.strings = c("","NA", "NULL"))
```
####Exploration showed they are lot of NA's, Null
```{r}
  naprops <- colSums(is.na(trainDataRaw))/nrow(trainDataRaw) 
```
####Let see the amount NAs and Null present
```{r}
  napercent <- colSums(is.na(trainDataRaw))/nrow(trainDataRaw)
  head(napercent)
```
there are about 98% of NA's, and we exclude this to make prediction data clean, excluding NNA
```{r}
  ptrainDataNNA <- trainDataRaw[,colSums(is.na(trainDataRaw)) == 0]
```

we exclude these columns, these colums which are not used for prediction analysis.
>excluding data with are not use full for analysis NAs and etc  
*$ X                       : int  1 2 3 4 5 6 7 8 9 10 ...  
*$ user_name               : Factor w/ 6 levels "adelmo","carlitos",..: 2 2 2 2 2 2 2 2 2 2 ...  
*$ raw_timestamp_part_1    : int  1323084231 1323084231 1323084231 1323084232 1323084232 1323084232 1323084232 1323084232 1323084232  
*$ raw_timestamp_part_2    : int  788290 808298 820366 120339 196328 304277 368296 440390 484323 484434 ...  
*$ cvtd_timestamp          : Factor w/ 20 levels "02/12/2011 13:32",..: 9 9 9 9 9 9 9 9 9 9 ...  
*$ new_window              : Factor w/ 2 levels "no","yes": 1 1 1 1 1 1 1 1 1 1 ...  
*$ num_window              : int  11 11 11 12 12 12 12 12 12 12 ...

```{r}
  predicitiontrain <- ptrainDataNNA[,8:length(ptrainDataNNA[1,])]
```

##### check for Non zero variance predictors, and exclude them since not used for prediction
```{r}
  nzvColumn <-  which(nearZeroVar(predicitiontrain, saveMetrics = TRUE)$nzv == FALSE)
  predicitiontrainNZV <- predicitiontrain[,nzvColumn]
```

##### exclude highly correlated variables helps us to build model with required varaibles, 90% in this test case.
##### Get the correlation between each varaible and get high correlations and remove them
```{r}
  corrMatrix<- cor(predicitiontrainNZV[,sapply(predicitiontrainNZV, is.numeric)])
  highcorrvb<- findCorrelation(corrMatrix, cutoff = 0.9, verbose = TRUE)
  predicitionDataSet<- predicitiontrainNZV[,-highcorrvb]
  dim(predicitionDataSet)
```

#Model for prediction

##### split the data for cross validation
```{r}
  inTrain <- createDataPartition(predicitionDataSet$classe, p = 3/4, list = FALSE)
  training <- predicitionDataSet[inTrain,]
  testing <- predicitionDataSet[-inTrain,]
```

```{r}
## analyze the data with caret package
modrpart <- train(classe ~., method = "rpart", data = training)
print(modrpart$finalModel)
  
```

#####Plot Classification Tree
```{r, echo=FALSE, fig.height=7, fig.width=7, fig.align='left'}
plot(modrpart$finalModel, uniform = TRUE, main = "Classification Tree")
text(modrpart$finalModel, use.n = TRUE, all = FALSE, cex = 0.8)
```

#####check accuracy, which is near 50% not encouraging to prediction model
```{r}
  predrpart <- predict(modrpart, testing)
  table(predrpart, testing$classe)
  confusionMatrix(testing$classe, predrpart)$overall['Accuracy']
```

###GDM (Generalized boosted Regression Model) Prediction
  
##### The predict returns back the probability for each classe, Below for each row we pick the one with largest probability,
##### the accuracy is about 77%.
```{r}
  modgbm <- gbm(classe ~., data = training, distribution = "multinomial", n.trees = 200, interaction.depth = 4, shrinkage = 0.005)
  predgbm <- predict(modgbm, n.trees = 200, newdata= testing, type = 'response')
  maxpredgbm <- apply(predgbm, 1, which.max)
```

```{r}
  ## Since 1~5 means A ~ E, we rename them below
  maxpredgbm[which(maxpredgbm == 1)] <- "A"
  maxpredgbm[which(maxpredgbm == 2)] <- "B"
  maxpredgbm[which(maxpredgbm == 3)] <- "C"
  maxpredgbm[which(maxpredgbm == 4)] <- "D"
  maxpredgbm[which(maxpredgbm == 5)] <- "E"
  maxpredgbm <- as.factor(maxpredgbm)
```

```{r}
  # check the accuracy using confusionMatrix
  confusionMatrix(testing$classe, maxpredgbm)$overall['Accuracy']
```

###Random Forest Prediction, the accurancy obout 99%
```{r}
  library(randomForest)
  modrf <- randomForest(classe~., data = training, ntree=100, importance=TRUE, prox = TRUE)
  predrf <- predict(modrf, testing)
  table(predrf, testing$classe)
  confusionMatrix(testing$classe, predrf)$overall['Accuracy']
```

